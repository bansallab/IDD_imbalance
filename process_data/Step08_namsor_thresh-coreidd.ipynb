{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119f2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ethnicolr as ec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pypopulation\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import statistics\n",
    "import statistics\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import os \n",
    "os.chdir(\"/Users/alexesmerritt/Library/CloudStorage/GoogleDrive-akm147@georgetown.edu/My Drive/citation_bias/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"dworkin_code_api/coreidd/df7_articledata_withgenders.csv\")\n",
    "df0[['FALN','FAFN']] = df0['first_auth'].str.split(', ', expand=True)\n",
    "df0['first_auth']=df0['FAFN']+' '+df0['FALN']\n",
    "\n",
    "\n",
    "df0[['LALN','LAFN']] = df0['last_auth'].str.split(', ', expand=True)\n",
    "df0['last_auth']=df0['LAFN']+' '+df0['LALN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58401049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FArace=pd.read_csv('namsor_inputs/namsor_full-name-us-race_highlycited_processed_namsor_input.csv')\n",
    "df_FArace=df_FArace[['name','raceEthnicity','probabilityCalibrated']]\n",
    "\n",
    "df_LArace=pd.read_csv('namsor_inputs/namsor_full-name-us-race_highlycited_processed_namsor_input (1).csv')\n",
    "df_LArace=df_LArace[['name','raceEthnicity','probabilityCalibrated']]\n",
    "\n",
    "\n",
    "df_namsor_race= pd.concat([df_FArace, df_LArace])\n",
    "df_namsor_race = df_namsor_race.sort_values('probabilityCalibrated',ascending=False).drop_duplicates(subset=['name'])\n",
    "\n",
    "df_new_namsor_race=pd.read_csv(\"dworkin_code_api/coreidd/namsor_race_output_coreidd.csv\")\n",
    "df_new_namsor_race=df_new_namsor_race[['name','raceEthnicity','probabilityCalibrated']]\n",
    "\n",
    "df_namsor_race=pd.concat([df_namsor_race,df_new_namsor_race])\n",
    "df_namsor_race = df_namsor_race.sort_values('probabilityCalibrated',ascending=False).drop_duplicates(subset=['name'])\n",
    "\n",
    "\n",
    "\n",
    "namsor_race=dict(zip(df_namsor_race.name.str.lower(), df_namsor_race.raceEthnicity))\n",
    "namsor_race_prob=dict(zip(df_namsor_race.name.str.lower(),df_namsor_race.probabilityCalibrated))\n",
    "\n",
    "\n",
    "df0['first_auth']=df0['first_auth'].str.lower()\n",
    "df0['FA_race'] = df0['first_auth'].map(namsor_race)\n",
    "df0['FA_race_prob'] = df0['first_auth'].map(namsor_race_prob)\n",
    "\n",
    "df0['last_auth']=df0['last_auth'].str.lower()\n",
    "df0['LA_race'] = df0['last_auth'].map(namsor_race)\n",
    "df0['LA_race_prob'] = df0['last_auth'].map(namsor_race_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FAgender=pd.read_csv('namsor_inputs/namsor_genderize-full-name_highlycited_processed_namsor_input.csv')\n",
    "df_FAgender=df_FAgender[['name','likelyGender','probabilityCalibrated']]\n",
    "\n",
    "\n",
    "df_LAgender=pd.read_csv('namsor_inputs/namsor_genderize-full-name_highlycited_processed_namsor_input (1).csv')\n",
    "df_LAgender=df_LAgender[['name','likelyGender','probabilityCalibrated']]\n",
    "\n",
    "\n",
    "df_namsor_gender= pd.concat([df_FAgender, df_LAgender])\n",
    "df_namsor_gender = df_namsor_gender.sort_values('probabilityCalibrated',ascending=False).drop_duplicates(subset=['name'])\n",
    "\n",
    "\n",
    "df_new_namsor_gender=pd.read_csv(\"dworkin_code_api/coreidd/namsor_gender_output_coreidd.csv\")\n",
    "df_new_namsor_gender=df_new_namsor_gender[['name','likelyGender','probabilityCalibrated']]\n",
    "df_namsor_gender=pd.concat([df_namsor_gender,df_new_namsor_gender])\n",
    "df_namsor_gender = df_namsor_gender.sort_values('probabilityCalibrated',ascending=False).drop_duplicates(subset=['name'])\n",
    "\n",
    "namsor_gender=dict(zip(df_namsor_gender.name.str.lower(), df_namsor_gender.likelyGender))\n",
    "namsor_gender_prob=dict(zip(df_namsor_gender.name.str.lower(),df_namsor_gender.probabilityCalibrated))\n",
    "\n",
    "\n",
    "df0['first_auth']=df0['first_auth'].str.lower()\n",
    "df0['FA_gender'] = df0['first_auth'].map(namsor_gender)\n",
    "df0['FA_gender_prob'] = df0['first_auth'].map(namsor_gender_prob)\n",
    "\n",
    "df0['last_auth']=df0['last_auth'].str.lower()\n",
    "df0['LA_gender'] = df0['last_auth'].map(namsor_gender)\n",
    "df0['LA_gender_prob'] = df0['last_auth'].map(namsor_gender_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.to_csv(\"dworkin_code_api/coreidd/namsor_completed_df7.5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a3b9304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160228"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"dworkin_code_api/coreidd/namsor_completed_df7.5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d103065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you will see a series of runs of the same program, ethnicolr times out and had problems with large datasets.\n",
    "### To work around this we ran the datasets and then find which names it wasnt able to produce a prediction for.\n",
    "### Getting this took us 4 rounds of ethnicolr.\n",
    "\n",
    "#Creating Dataframes\n",
    "df_LA=df[['UT','LALN','LAFN']]\n",
    "df_FA=df[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 1 FA\n",
    "results_FA = ec.pred_fl_reg_name(df_FA, 'FALN', 'FAFN')\n",
    "results_FA=results_FA.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 1 LA\n",
    "results_LA = ec.pred_fl_reg_name(df_LA, 'LALN', 'LAFN')\n",
    "results_LA=results_LA.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37bc9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 2\n",
    "\n",
    "#Finding Nan Papers\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "#Making Datasets\n",
    "\n",
    "df_FA_nan=df.loc[df['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df.loc[df['UT'].isin(UT_LA_nan)]\n",
    "\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 2 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 2 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e3c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Ethnicolr 1 and 2\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534fdebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 3\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df.loc[df['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df.loc[df['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 3 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 3 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39481eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Results from 1&2 with 3\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e993605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 4\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df.loc[df['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df.loc[df['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 4 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 4 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46ec21be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hispanic' 'nh_white' 'nh_black' 'asian' nan]\n",
      "Index(['Unnamed: 0', 'AF', 'SO', 'DI', 'PY', 'PD', 'DT', 'WC', 'UT', 'TC',\n",
      "       'PM', 'TI', 'done', 'fa_fname', 'la_fname', 'prob.m.fa', 'prob.w.fa',\n",
      "       'prob.m.la', 'prob.w.la', 'first_auth', 'last_auth', 'FALN', 'FAFN',\n",
      "       'LALN', 'LAFN', 'FA_race', 'FA_prob_race', 'LA_race', 'LA_prob_race',\n",
      "       'FA_gender', 'FA_prob_gender', 'LA_gender', 'LA_prob_gender',\n",
      "       'FA_ethni_race', 'LA_ethni_race', 'FA_ethni_prop', 'LA_ethni_prop'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m df_comp\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlexes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Section/Prethresholding_HC.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m df_UT\u001b[38;5;241m=\u001b[39mdf_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 35\u001b[0m df_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_' is not defined"
     ]
    }
   ],
   "source": [
    "#Merging Results from 1,2,3 with 4\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "results=results_LA.merge(results_FA,on='UT',how='outer')\n",
    "\n",
    "results['LA_ethni_prop']=''\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='asian']=results['LA_asian'].loc[results['LA_ethni_race']=='asian']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_white']=results['LA_white'].loc[results['LA_ethni_race']=='nh_white']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='hispanic']=results['LA_hispanic'].loc[results['LA_ethni_race']=='hispanic']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_black']=results['LA_black'].loc[results['LA_ethni_race']=='nh_black']\n",
    "\n",
    "results['FA_ethni_prop']=''\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='asian']=results['FA_asian'].loc[results['FA_ethni_race']=='asian']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_white']=results['FA_white'].loc[results['FA_ethni_race']=='nh_white']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='hispanic']=results['FA_hispanic'].loc[results['FA_ethni_race']=='hispanic']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_black']=results['FA_black'].loc[results['FA_ethni_race']=='nh_black']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(results['FA_ethni_race'].unique())\n",
    "\n",
    "results=results[['UT','FA_ethni_race','LA_ethni_race','FA_ethni_prop','LA_ethni_prop']]\n",
    "df_comp=df.merge(results,on='UT',how='outer')\n",
    "df_comp=df_comp.replace({'nh_white':'W_NL', 'asian':'A', 'hispanic':\"HL\", 'nh_black':'B_NL'})\n",
    "\n",
    "df_comp=df_comp.rename(columns={'LA_race_prob':'LA_prob_race','FA_race_prob':'FA_prob_race'})\n",
    "df_comp=df_comp.rename(columns={'LA_gender_prob':'LA_prob_gender','FA_gender_prob':'FA_prob_gender'})\n",
    "print(df_comp.columns)\n",
    "df_comp.to_csv(\"Alexes' Section/Prethresholding_HC.csv\")\n",
    "\n",
    "# Outputing a file that has results for the papers wherever possible and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd18ee1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_comp=pd.read_csv(\"Alexes' Section/Prethresholding_HC.csv\")\n",
    "df_UT=df_comp[['UT']]\n",
    "print(len(df_comp.loc[df_comp['UT'].isna()]))\n",
    "\n",
    "df_UT['UT']=df_UT['UT'].str.replace('WOS', 'UT', regex=True)\n",
    "print(len(df_UT.loc[df_UT['UT'].isna()]))\n",
    "df_UT['UT'].to_csv(\"Alexes' Section/HC_UT.txt\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e9956",
   "metadata": {},
   "source": [
    "# Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d774b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############REPEATING ALL THE PREVIOUS STEPS FOR OUR DEFINITION OF THE FIELD BASED ON BOOKS.\n",
    "df0 = pd.read_csv(\"/dworkin_code_api/books/df7_articledata_withgenders.csv\")\n",
    "\n",
    "df_FAgender=pd.read_csv('/namsor_inputs/namsor_genderize-full-name_books_processed_namsor_input.csv')\n",
    "df_FAgender=df_FAgender.rename(columns={'likelyGender':'FA_gender', 'probabilityCalibrated':'FA_prob_gender'})\n",
    "df_FAgender=df_FAgender[['UT','FA_gender', 'FA_prob_gender']]\n",
    "\n",
    "df_LAgender=pd.read_csv('/namsor_inputs/namsor_genderize-full-name_books_processed_namsor_input (1).csv')\n",
    "df_LAgender=df_LAgender.rename(columns={'likelyGender':'LA_gender', 'probabilityCalibrated':'LA_prob_gender'})\n",
    "df_LAgender=df_LAgender[['UT','LA_gender', 'LA_prob_gender']]\n",
    "\n",
    "df0=df0.merge(df_FAgender,on='UT',how='outer')\n",
    "df0=df0.merge(df_LAgender,on='UT',how='outer')\n",
    "\n",
    "df_FArace=pd.read_csv('/namsor_inputs/namsor_full-name-us-race_books_processed_namsor_input.csv')\n",
    "df_FArace=df_FArace.rename(columns={'raceEthnicityAlt':'FA_race2', 'raceEthnicity':'FA_race',\n",
    "                                    'probabilityCalibrated':'FA_prob_race','probabilityAltCalibrated':'FA_prob2'})\n",
    "df_FArace=df_FArace[['UT','FA_race2', 'FA_race', 'FA_prob_race', 'FA_prob2']]\n",
    "\n",
    "df_LArace=pd.read_csv('/namsor_inputs/namsor_full-name-us-race_books_processed_namsor_input (1).csv')\n",
    "df_LArace=df_LArace.rename(columns={'raceEthnicityAlt':'LA_race2', 'raceEthnicity':'LA_race',\n",
    "                                    'probabilityCalibrated':'LA_prob_race','probabilityAltCalibrated':'LA_prob2'})\n",
    "df_LArace=df_LArace[['UT','LA_race2', 'LA_race', 'LA_prob_race', 'LA_prob2']]\n",
    "\n",
    "df0=df0.merge(df_FArace,on='UT',how='outer')\n",
    "df0=df0.merge(df_LArace,on='UT',how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224570ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kabir, M. Humayun' 'Elsadany, A. A.' 'Igoe, Morganne' ...\n",
      " 'MITSUYA, Hiroaki' 'NEEQUAYE, AR' 'BELSEY, MA']\n"
     ]
    }
   ],
   "source": [
    "df=df0\n",
    "\n",
    "df['first_auth'] = df['first_auth'].astype(str)\n",
    "df['last_auth'] = df['last_auth'].astype(str)\n",
    "FAl=list(df['first_auth'])\n",
    "LAl=list(df['last_auth'])\n",
    "\n",
    "df['FAFN']=''\n",
    "df['FALN']=''\n",
    "df['LAFN']=''\n",
    "df['LALN']=''\n",
    "FAFN=list(df['FAFN'])\n",
    "FALN=list(df['FALN'])\n",
    "LAFN=list(df['LAFN'])\n",
    "LALN=list(df['LALN'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(df)): \n",
    "    if ', ' in LAl[i]:\n",
    "        LA=LAl[i].split(', ')\n",
    "        LAl[i]=LA[1]+' '+LA[0]\n",
    "        LAFN[i]=LA[1]\n",
    "        LALN[i]=LA[0]\n",
    "    if ', ' in FAl[i]:\n",
    "        FA=FAl[i].split(', ')\n",
    "        FAl[i]=FA[1]+' '+LA[0]\n",
    "        FAFN[i]=FA[1]\n",
    "        FALN[i]=FA[0]\n",
    "\n",
    "df['FAFN']=FAFN\n",
    "df['FALN']=FALN\n",
    "df['LAFN']=LAFN\n",
    "df['LALN']=LALN\n",
    "        \n",
    "df['FAFN']=df['FAFN'].str.title()\n",
    "df['FALN']=df['FALN'].str.title()\n",
    "df['LAFN']=df['LAFN'].str.title()\n",
    "df['LALN']=df['LALN'].str.title()\n",
    "print(df['first_auth'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Run of Ethnicolr\n",
    "\n",
    "#Creating Dataframes\n",
    "df_LA=df[['UT','LALN','LAFN']]\n",
    "df_FA=df[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 1 FA\n",
    "results_FA = ec.pred_fl_reg_name(df_FA, 'FALN', 'FAFN')\n",
    "results_FA=results_FA.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 1 LA\n",
    "results_LA = ec.pred_fl_reg_name(df_LA, 'LALN', 'LAFN')\n",
    "results_LA=results_LA.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38106d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 2\n",
    "\n",
    "#Finding Nan Papers\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "#Making Datasets\n",
    "\n",
    "df_FA_nan=df.loc[df['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df.loc[df['UT'].isin(UT_LA_nan)]\n",
    "\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 2 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 2 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Ethnicolr 1 and 2\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 3\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df0.loc[df0['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df0.loc[df0['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 3 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 3 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Results from 1&2 with 3\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 4\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df0.loc[df0['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df0.loc[df0['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 4 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 4 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3839781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Results from 1,2,3 with 4\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "results=results_LA.merge(results_FA,on='UT',how='outer')\n",
    "\n",
    "results['LA_ethni_prop']=''\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='asian']=results['LA_asian'].loc[results['LA_ethni_race']=='asian']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_white']=results['LA_white'].loc[results['LA_ethni_race']=='nh_white']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='hispanic']=results['LA_hispanic'].loc[results['LA_ethni_race']=='hispanic']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_black']=results['LA_black'].loc[results['LA_ethni_race']=='nh_black']\n",
    "\n",
    "results['FA_ethni_prop']=''\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='asian']=results['FA_asian'].loc[results['FA_ethni_race']=='asian']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_white']=results['FA_white'].loc[results['FA_ethni_race']=='nh_white']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='hispanic']=results['FA_hispanic'].loc[results['FA_ethni_race']=='hispanic']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_black']=results['FA_black'].loc[results['FA_ethni_race']=='nh_black']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(results['FA_ethni_race'].unique())\n",
    "\n",
    "results=results[['UT','FA_ethni_race','LA_ethni_race','FA_ethni_prop','LA_ethni_prop']]\n",
    "df_comp=df.merge(results,on='UT',how='outer')\n",
    "df_comp=df_comp.replace({'nh_white':'W_NL', 'asian':'A', 'hispanic':\"HL\", 'nh_black':'B_NL'})\n",
    "df_comp.to_csv(\"Alexes' Section/Prethresholding_books.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63f06d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_comp=pd.read_csv(\"Alexes' Section/Prethresholding_books.csv\")\n",
    "df_UT=df_comp[['UT']]\n",
    "df_UT['UT']=df_UT['UT'].str.replace('WOS', 'UT', regex=True)\n",
    "df_UT['UT'].to_csv(\"Alexes' Section/books_UT.txt\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b444611",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8751f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUnction that will group and threshold different any of the datasets\n",
    "\"/Users/alexesmerritt/Library/CloudStorage/GoogleDrive-akm147@georgetown.edu/My Drive/citation_bias/\"\n",
    "def thresholding(threshold,dataset):\n",
    "    df=pd.read_csv(\"Alexes' Section/Prethresholding_\"+dataset+\".csv\")\n",
    "    ########################### THRESHOLDING FOR RACE ###########################\n",
    "    non_white =['A', 'HL', 'B_NL']\n",
    "    ######## Grouping namsore Race outputs\n",
    "    #creating column to save output\n",
    "    df['FA_group']=''\n",
    "    df['LA_group']=''\n",
    "    ##Putting asian, hispanic and black authors in the nonwhite category 'N'\n",
    "    df['FA_group'].loc[df['FA_race'].isin(non_white)] = \"N\"\n",
    "    df['LA_group'].loc[df['LA_race'].isin(non_white)] = \"N\"\n",
    "\n",
    "    ## Putting white authors as white in grouping columns\n",
    "    df['FA_group'].loc[df['FA_race'] == 'W_NL'] = \"W\"\n",
    "    df['LA_group'].loc[df['LA_race'] == 'W_NL'] = \"W\"\n",
    "    \n",
    "    \n",
    "    ######## Repeating process for Ethnicolr results\n",
    "    df['FA_group_e']=''\n",
    "    df['LA_group_e']=''\n",
    "    df['FA_group_e'].loc[df['FA_ethni_race'].isin(non_white)] = \"N\"\n",
    "    df['LA_group_e'].loc[df['LA_ethni_race'].isin(non_white)] = \"N\"\n",
    "    df['FA_group_e'].loc[df['FA_ethni_race'] == 'W_NL'] = \"W\"\n",
    "    df['LA_group_e'].loc[df['LA_ethni_race'] == 'W_NL'] = \"W\"\n",
    "    df['FA_ethni_prop']=pd.to_numeric(df['FA_ethni_prop'], errors='coerce')\n",
    "    df['LA_ethni_prop']=pd.to_numeric(df['LA_ethni_prop'], errors='coerce')\n",
    "    \n",
    "    ####################### SIMPLIFYING NAMSOR GENDER RESULT #################\n",
    "    df['LA_gender']=df['LA_gender'].replace({'female':'W','male':'M'})\n",
    "    df['FA_gender']=df['FA_gender'].replace({'female':'W','male':'M'})\n",
    "\n",
    "    ############################## THRESHOLDING ############################\n",
    "    \n",
    "    df['FA_group_e'].loc[df['FA_ethni_prop']<threshold] = 'U'\n",
    "    df['FA_group_e'].loc[df['FA_ethni_prop'].isna()] = 'U'\n",
    "    df['LA_group_e'].loc[df['LA_ethni_prop']<threshold] = 'U'\n",
    "    df['LA_group_e'].loc[df['LA_ethni_prop'].isna()] = 'U'\n",
    "    df['groups_e']=df['FA_group_e']+df['LA_group_e']\n",
    "\n",
    "    df['FA_ethni_race'].loc[df['FA_ethni_prop']<threshold] = 'U'\n",
    "    df['LA_ethni_race'].loc[df['LA_ethni_prop']<threshold] = 'U'\n",
    "    df['FA_ethni_race'].loc[df['FA_ethni_prop'].isna()] = 'U'\n",
    "    df['LA_ethni_race'].loc[df['LA_ethni_prop'].isna()] = 'U'\n",
    "\n",
    "    df['FA_group'].loc[df['FA_prob_race']<threshold] = 'U'\n",
    "    df['LA_group'].loc[df['LA_prob_race']<threshold] = 'U'\n",
    "    df['FA_group'].loc[df['FA_prob_race'].isna()] = 'U'\n",
    "    df['LA_group'].loc[df['LA_prob_race'].isna()] = 'U'\n",
    "    df['groups']=df['FA_group']+df['LA_group']\n",
    "\n",
    "    df['FA_race'].loc[df['FA_prob_race']<threshold] = 'U'\n",
    "    df['LA_race'].loc[df['LA_prob_race']<threshold] = 'U'\n",
    "    df['FA_race'].loc[df['FA_prob_race'].isna()] = 'U'\n",
    "    df['LA_race'].loc[df['LA_prob_race'].isna()] = 'U'\n",
    "    \n",
    "    df['FA_gender'].loc[df['FA_prob_gender']<threshold] = 'U'\n",
    "    df['FA_gender'].loc[df['FA_prob_gender'].isna()] = 'U'\n",
    "    df['LA_gender'].loc[df['LA_prob_gender']<threshold] = 'U'\n",
    "    df['LA_gender'].loc[df['LA_prob_gender'].isna()] = 'U'\n",
    "    df['AG_namsor']=df['FA_gender']+df['LA_gender']\n",
    "    \n",
    "    \n",
    "    df['FA_group_g']='U'\n",
    "    df['FA_group_g'].loc[df['prob.w.fa']>=threshold]='W'\n",
    "    df['FA_group_g'].loc[df['prob.m.fa']>=threshold]='M'\n",
    "\n",
    "    df['LA_group_g']='U'\n",
    "    df['LA_group_g'].loc[df['prob.w.la']>=threshold]='W'\n",
    "    df['LA_group_g'].loc[df['prob.m.la']>=threshold]='M'\n",
    "    df['AG']=df['FA_group_g']+df['LA_group_g']\n",
    "    \n",
    "    #### SETTING PAPERS AS GLOBAL NORTH BASED ON LAST AUTHOR AFFILIATION\n",
    "   # definition of global north comes from:\n",
    "    # https://unctadstat.unctad.org/EN/Classifications/DimCountries_All_Hierarchy.pdf\n",
    "    westernworld=[ 'Bermuda','Canada','Greenland','USA','Cyprus','Israel','Australia',\n",
    "                  'Christmas Island','Cocos Island','Heard Island and McDonald Island','New Zealand',\n",
    "                  'Norfolk Island','United States Minor Outlying Islands','Aland Islands','Albania','Andorra',\n",
    "                  'Austria','Belarus','Belgium','Bosnia and Herzegovina','Bulgaria','Croatia','Czechia',\n",
    "                  'Czechoslovakia','Germany','Denmark','Estonia','Faroe Islands','Finland','France','Gibraltar',\n",
    "                 'Greece','Guernsey','Holy See','Hungary','Holy See','Hungary','Iceland','Ireland','Isle of Man',\n",
    "                 'Italy','Jersey','Kosovo','Latvia','Liechtenstein','Lithuania','Luxembourg','Malta','Monaco',\n",
    "                  'Montenegro','Netherlands','North Macedonia','Norway','Poland','Portugal',\n",
    "                  'Republic of Macedonia','Romania','Russia','San Marino','Serbia','Serbia and Montenegro',\n",
    "                 'Slovakia','Slovenia','Spain','Svalbard and Jan Mayen Islands','Sweden','Switzerland','Ukraine',\n",
    "                 'United Kingdom','Yugoslavia']\n",
    "    westernworld=[x.lower() for x in westernworld]\n",
    "    if dataset=='HC':\n",
    "        df_country=pd.read_csv(\"Alexes' Section/coreidd_exporter/HC_countries.csv\")\n",
    "    elif dataset=='books':\n",
    "        df_country=pd.read_csv(\"Alexes' Section/coreidd_exporter/books_countries.csv\")\n",
    "        \n",
    "    df_country=df_country.rename(columns={'Accession Number (UT)':'UT'})\n",
    "    df_country=df_country[['UT','Country','Researcher/Author SeqNo (position)']]\n",
    "    df_country=df_country.sort_values(by=['UT','Researcher/Author SeqNo (position)']).drop_duplicates(subset=['UT'],keep='last')\n",
    "    df_country=df_country[['UT','Country']]\n",
    "    df=pd.merge(df,df_country,how='left',on='UT')\n",
    "    \n",
    "    df['Country'] = df['Country'].str.lower()\n",
    "    ## Editing countries to correct names or update to new names\n",
    "    df['Country']=df['Country'].replace({'czech republic':'czechia','new caledonia':'france',\n",
    "                                         'england':'United Kingdom (Great Britain)',\n",
    "                                         'north ireland':'United Kingdom (Great Britain)',\n",
    "                                         'wales':'United Kingdom (Great Britain)',\n",
    "                                         'scotland':'United Kingdom (Great Britain)',\n",
    "                                        'french guiana':'France','u arab emirates':'UAE',\n",
    "                                        'dominican rep':'Dominican Republic',\n",
    "                                         'dem rep congo':'Democratic Republic of Congress',\n",
    "                                        'rep congo':'Republic of Congo','fed rep ger':'Germany',\n",
    "                                        'west germany':'Germany','austl.':'Australia',\n",
    "                                        'serbia monteneg':'Serbia and Montenegro','ussr':'Russia',\n",
    "                                         'cent afr republ':'Central African Republic',\n",
    "                                        'deutsch dem rep':'Germany','ger dem rep':'Germany',\n",
    "                                        'ukssr':'Ukraine','east germany':'Germany','united arab rep':'UAE',\n",
    "                                        'trin + tobago':'Trinidad and Tobago','trinidad tobago':'Trinidad and Tobago'})\n",
    "    \n",
    "    df['Country'] = df['Country'].str.lower()\n",
    "    df['global_north']=0\n",
    "    df['global_north'].loc[df['Country'].isin(westernworld)]=1\n",
    "\n",
    "    if dataset=='HC':\n",
    "        dataset='highlycited'\n",
    "        df.to_csv(\"dworkin_code_api/coreidd/df8_\"+dataset+\"_\"+str(threshold)+'.csv')\n",
    "    else: \n",
    "        df.to_csv(\"dworkin_code_api/books/\"+dataset+\"_\"+str(threshold)+'.csv')\n",
    "\n",
    "thresholding(.7,'HC')\n",
    "thresholding(.6,'HC')\n",
    "thresholding(.8,'HC')\n",
    "thresholding(.7,'books')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
