{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "119f2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ethnicolr as ec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pypopulation\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import statistics\n",
    "import statistics\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import os \n",
    "os.chdir(\"/Users/alexesmerritt/Library/CloudStorage/GoogleDrive-akm147@georgetown.edu/My Drive/citation_bias/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01df84e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AF', 'SO', 'DI', 'PY', 'PD', 'DT', 'WC', 'UT', 'TC', 'PM', 'done',\n",
      "       'fa_fname', 'la_fname', 'prob.m.fa', 'prob.w.fa', 'prob.m.la',\n",
      "       'prob.w.la', 'first_auth', 'last_auth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "####################### READING IN RESULTS FROM NAMSOR AND STEP 7 ####################################\n",
    "\n",
    "df0 = pd.read_csv(\"dworkin_code_api/highlycited/df7_articledata_withgenders.csv\")\n",
    "\n",
    "      \n",
    "# FIRST AUTHOR GENDER FILES\n",
    "df_FAgender=pd.read_csv('namsor_inputs/namsor_genderize-full-name_highlycited_processed_namsor_input.csv')\n",
    "df_FAgender=df_FAgender.rename(columns={'likelyGender':'FA_gender', 'probabilityCalibrated':'FA_prob_gender'})\n",
    "df_FAgender=df_FAgender[['UT','FA_gender', 'FA_prob_gender']]\n",
    "\n",
    "# LAST AUTHOR GENDER FILES\n",
    "df_LAgender=pd.read_csv('namsor_inputs/namsor_genderize-full-name_highlycited_processed_namsor_input (1).csv')\n",
    "df_LAgender=df_LAgender.rename(columns={'likelyGender':'LA_gender', 'probabilityCalibrated':'LA_prob_gender'})\n",
    "df_LAgender=df_LAgender[['UT','LA_gender', 'LA_prob_gender']]\n",
    "\n",
    "df0=df0.merge(df_FAgender,on='UT',how='outer')\n",
    "df0=df0.merge(df_LAgender,on='UT',how='outer')\n",
    "\n",
    "# FIRST AUTHOR RACE FILES\n",
    "df_FArace=pd.read_csv('namsor_inputs/namsor_full-name-us-race_highlycited_processed_namsor_input.csv')\n",
    "df_FArace=df_FArace.rename(columns={'raceEthnicityAlt':'FA_race2', 'raceEthnicity':'FA_race',\n",
    "                                    'probabilityCalibrated':'FA_prob_race','probabilityAltCalibrated':'FA_prob2'})\n",
    "df_FArace=df_FArace[['UT','FA_race2', 'FA_race', 'FA_prob_race', 'FA_prob2']]\n",
    "\n",
    "      \n",
    "# LAST AUTHOR RACE FILES\n",
    "df_LArace=pd.read_csv('namsor_inputs/namsor_full-name-us-race_highlycited_processed_namsor_input (1).csv')\n",
    "df_LArace=df_LArace.rename(columns={'raceEthnicityAlt':'LA_race2', 'raceEthnicity':'LA_race',\n",
    "                                    'probabilityCalibrated':'LA_prob_race','probabilityAltCalibrated':'LA_prob2'})\n",
    "df_LArace=df_LArace[['UT','LA_race2', 'LA_race', 'LA_prob_race', 'LA_prob2']]\n",
    "###ALL DATA IN ONE FILE\n",
    "df0=df0.merge(df_FArace,on='UT',how='outer')\n",
    "df0=df0.merge(df_LArace,on='UT',how='outer')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da5ebea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bi, Jichao' 'Zhou, Yingjie' 'Song, Yutong' ... 'STROBEL, Gary A.'\n",
      " 'FELLOUS, Marc' 'COLE, Tim J.']\n"
     ]
    }
   ],
   "source": [
    "df=df0\n",
    "####################### ORGANIZING AUTHOR FIRST AND LAST NAME FOR ETHNICOLR ##################################\n",
    "df['first_auth'] = df['first_auth'].astype(str)\n",
    "df['last_auth'] = df['last_auth'].astype(str)\n",
    "FAl=list(df['first_auth'])\n",
    "LAl=list(df['last_auth'])\n",
    "\n",
    "df['FAFN']=''\n",
    "df['FALN']=''\n",
    "df['LAFN']=''\n",
    "df['LALN']=''\n",
    "FAFN=list(df['FAFN'])\n",
    "FALN=list(df['FALN'])\n",
    "LAFN=list(df['LAFN'])\n",
    "LALN=list(df['LALN'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(df)): \n",
    "    if ', ' in LAl[i]:\n",
    "        LA=LAl[i].split(', ')\n",
    "        LAl[i]=LA[1]+' '+LA[0]\n",
    "        LAFN[i]=LA[1]\n",
    "        LALN[i]=LA[0]\n",
    "    if ', ' in FAl[i]:\n",
    "        FA=FAl[i].split(', ')\n",
    "        FAl[i]=FA[1]+' '+LA[0]\n",
    "        FAFN[i]=FA[1]\n",
    "        FALN[i]=FA[0]\n",
    "\n",
    "df['FAFN']=FAFN\n",
    "df['FALN']=FALN\n",
    "df['LAFN']=LAFN\n",
    "df['LALN']=LALN\n",
    "        \n",
    "df['FAFN']=df['FAFN'].str.title()\n",
    "df['FALN']=df['FALN'].str.title()\n",
    "df['LAFN']=df['LAFN'].str.title()\n",
    "df['LALN']=df['LALN'].str.title()\n",
    "print(df['first_auth'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d103065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you will see a series of runs of the same program, ethnicolr times out and had problems with large datasets.\n",
    "### To work around this we ran the datasets and then find which names it wasnt able to produce a prediction for.\n",
    "### Getting this took us 4 rounds of ethnicolr.\n",
    "\n",
    "#Creating Dataframes\n",
    "df_LA=df[['UT','LALN','LAFN']]\n",
    "df_FA=df[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 1 FA\n",
    "results_FA = ec.pred_fl_reg_name(df_FA, 'FALN', 'FAFN')\n",
    "results_FA=results_FA.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 1 LA\n",
    "results_LA = ec.pred_fl_reg_name(df_LA, 'LALN', 'LAFN')\n",
    "results_LA=results_LA.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37bc9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 2\n",
    "\n",
    "#Finding Nan Papers\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "#Making Datasets\n",
    "\n",
    "df_FA_nan=df0.loc[df0['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df0.loc[df0['UT'].isin(UT_LA_nan)]\n",
    "\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 2 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 2 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e3c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Ethnicolr 1 and 2\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "534fdebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 3\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df0.loc[df0['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df0.loc[df0['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 3 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 3 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39481eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Results from 1&2 with 3\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e993605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 4\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df0.loc[df0['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df0.loc[df0['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 4 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 4 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46ec21be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian' 'nh_white' 'hispanic' 'nh_black' nan]\n"
     ]
    }
   ],
   "source": [
    "#Merging Results from 1,2,3 with 4\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "results=results_LA.merge(results_FA,on='UT',how='outer')\n",
    "\n",
    "results['LA_ethni_prop']=''\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='asian']=results['LA_asian'].loc[results['LA_ethni_race']=='asian']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_white']=results['LA_white'].loc[results['LA_ethni_race']=='nh_white']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='hispanic']=results['LA_hispanic'].loc[results['LA_ethni_race']=='hispanic']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_black']=results['LA_black'].loc[results['LA_ethni_race']=='nh_black']\n",
    "\n",
    "results['FA_ethni_prop']=''\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='asian']=results['FA_asian'].loc[results['FA_ethni_race']=='asian']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_white']=results['FA_white'].loc[results['FA_ethni_race']=='nh_white']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='hispanic']=results['FA_hispanic'].loc[results['FA_ethni_race']=='hispanic']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_black']=results['FA_black'].loc[results['FA_ethni_race']=='nh_black']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(results['FA_ethni_race'].unique())\n",
    "\n",
    "results=results[['UT','FA_ethni_race','LA_ethni_race','FA_ethni_prop','LA_ethni_prop']]\n",
    "df_comp=df.merge(results,on='UT',how='outer')\n",
    "df_comp=df_comp.replace({'nh_white':'W_NL', 'asian':'A', 'hispanic':\"HL\", 'nh_black':'B_NL'})\n",
    "df_comp.to_csv(\"Alexes' Section/Prethresholding_HC.csv\")\n",
    "# Outputing a file that has results for the papers wherever possible and "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e9956",
   "metadata": {},
   "source": [
    "# Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d774b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############REPEATING ALL THE PREVIOUS STEPS FOR OUR DEFINITION OF THE FIELD BASED ON BOOKS.\n",
    "df0 = pd.read_csv(\"/dworkin_code_api/books/df7_articledata_withgenders.csv\")\n",
    "\n",
    "df_FAgender=pd.read_csv('/namsor_inputs/namsor_genderize-full-name_books_processed_namsor_input.csv')\n",
    "df_FAgender=df_FAgender.rename(columns={'likelyGender':'FA_gender', 'probabilityCalibrated':'FA_prob_gender'})\n",
    "df_FAgender=df_FAgender[['UT','FA_gender', 'FA_prob_gender']]\n",
    "\n",
    "df_LAgender=pd.read_csv('/namsor_inputs/namsor_genderize-full-name_books_processed_namsor_input (1).csv')\n",
    "df_LAgender=df_LAgender.rename(columns={'likelyGender':'LA_gender', 'probabilityCalibrated':'LA_prob_gender'})\n",
    "df_LAgender=df_LAgender[['UT','LA_gender', 'LA_prob_gender']]\n",
    "\n",
    "df0=df0.merge(df_FAgender,on='UT',how='outer')\n",
    "df0=df0.merge(df_LAgender,on='UT',how='outer')\n",
    "\n",
    "df_FArace=pd.read_csv('/namsor_inputs/namsor_full-name-us-race_books_processed_namsor_input.csv')\n",
    "df_FArace=df_FArace.rename(columns={'raceEthnicityAlt':'FA_race2', 'raceEthnicity':'FA_race',\n",
    "                                    'probabilityCalibrated':'FA_prob_race','probabilityAltCalibrated':'FA_prob2'})\n",
    "df_FArace=df_FArace[['UT','FA_race2', 'FA_race', 'FA_prob_race', 'FA_prob2']]\n",
    "\n",
    "df_LArace=pd.read_csv('/namsor_inputs/namsor_full-name-us-race_books_processed_namsor_input (1).csv')\n",
    "df_LArace=df_LArace.rename(columns={'raceEthnicityAlt':'LA_race2', 'raceEthnicity':'LA_race',\n",
    "                                    'probabilityCalibrated':'LA_prob_race','probabilityAltCalibrated':'LA_prob2'})\n",
    "df_LArace=df_LArace[['UT','LA_race2', 'LA_race', 'LA_prob_race', 'LA_prob2']]\n",
    "\n",
    "df0=df0.merge(df_FArace,on='UT',how='outer')\n",
    "df0=df0.merge(df_LArace,on='UT',how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224570ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kabir, M. Humayun' 'Elsadany, A. A.' 'Igoe, Morganne' ...\n",
      " 'MITSUYA, Hiroaki' 'NEEQUAYE, AR' 'BELSEY, MA']\n"
     ]
    }
   ],
   "source": [
    "df=df0\n",
    "\n",
    "df['first_auth'] = df['first_auth'].astype(str)\n",
    "df['last_auth'] = df['last_auth'].astype(str)\n",
    "FAl=list(df['first_auth'])\n",
    "LAl=list(df['last_auth'])\n",
    "\n",
    "df['FAFN']=''\n",
    "df['FALN']=''\n",
    "df['LAFN']=''\n",
    "df['LALN']=''\n",
    "FAFN=list(df['FAFN'])\n",
    "FALN=list(df['FALN'])\n",
    "LAFN=list(df['LAFN'])\n",
    "LALN=list(df['LALN'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(df)): \n",
    "    if ', ' in LAl[i]:\n",
    "        LA=LAl[i].split(', ')\n",
    "        LAl[i]=LA[1]+' '+LA[0]\n",
    "        LAFN[i]=LA[1]\n",
    "        LALN[i]=LA[0]\n",
    "    if ', ' in FAl[i]:\n",
    "        FA=FAl[i].split(', ')\n",
    "        FAl[i]=FA[1]+' '+LA[0]\n",
    "        FAFN[i]=FA[1]\n",
    "        FALN[i]=FA[0]\n",
    "\n",
    "df['FAFN']=FAFN\n",
    "df['FALN']=FALN\n",
    "df['LAFN']=LAFN\n",
    "df['LALN']=LALN\n",
    "        \n",
    "df['FAFN']=df['FAFN'].str.title()\n",
    "df['FALN']=df['FALN'].str.title()\n",
    "df['LAFN']=df['LAFN'].str.title()\n",
    "df['LALN']=df['LALN'].str.title()\n",
    "print(df['first_auth'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb49df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Run of Ethnicolr\n",
    "\n",
    "#Creating Dataframes\n",
    "df_LA=df[['UT','LALN','LAFN']]\n",
    "df_FA=df[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 1 FA\n",
    "results_FA = ec.pred_fl_reg_name(df_FA, 'FALN', 'FAFN')\n",
    "results_FA=results_FA.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 1 LA\n",
    "results_LA = ec.pred_fl_reg_name(df_LA, 'LALN', 'LAFN')\n",
    "results_LA=results_LA.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38106d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 2\n",
    "\n",
    "#Finding Nan Papers\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "#Making Datasets\n",
    "\n",
    "df_FA_nan=df0.loc[df0['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df0.loc[df0['UT'].isin(UT_LA_nan)]\n",
    "\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 2 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 2 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8eb7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Ethnicolr 1 and 2\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef2c352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 3\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df0.loc[df0['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df0.loc[df0['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 3 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 3 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61e2141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Results from 1&2 with 3\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1b7b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 4\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df0.loc[df0['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df0.loc[df0['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 4 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 4 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3839781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian' 'nh_white' 'hispanic' 'nh_black' nan]\n"
     ]
    }
   ],
   "source": [
    "#Merging Results from 1,2,3 with 4\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "results=results_LA.merge(results_FA,on='UT',how='outer')\n",
    "\n",
    "results['LA_ethni_prop']=''\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='asian']=results['LA_asian'].loc[results['LA_ethni_race']=='asian']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_white']=results['LA_white'].loc[results['LA_ethni_race']=='nh_white']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='hispanic']=results['LA_hispanic'].loc[results['LA_ethni_race']=='hispanic']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_black']=results['LA_black'].loc[results['LA_ethni_race']=='nh_black']\n",
    "\n",
    "results['FA_ethni_prop']=''\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='asian']=results['FA_asian'].loc[results['FA_ethni_race']=='asian']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_white']=results['FA_white'].loc[results['FA_ethni_race']=='nh_white']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='hispanic']=results['FA_hispanic'].loc[results['FA_ethni_race']=='hispanic']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_black']=results['FA_black'].loc[results['FA_ethni_race']=='nh_black']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(results['FA_ethni_race'].unique())\n",
    "\n",
    "results=results[['UT','FA_ethni_race','LA_ethni_race','FA_ethni_prop','LA_ethni_prop']]\n",
    "df_comp=df.merge(results,on='UT',how='outer')\n",
    "df_comp=df_comp.replace({'nh_white':'W_NL', 'asian':'A', 'hispanic':\"HL\", 'nh_black':'B_NL'})\n",
    "df_comp.to_csv(\"Alexes' Section/Prethresholding_books.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b444611",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8751f94b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FUnction that will group and threshold different any of the datasets\n",
    "def thresholding(threshold,dataset):\n",
    "    df=pd.read_csv(wd+'/Prethresholding_'+dataset+'.csv')\n",
    "    ########################### THRESHOLDING FOR RACE ###########################\n",
    "    non_white =['A', 'HL', 'B_NL']\n",
    "    ######## Grouping namsore Race outputs\n",
    "    #creating column to save output\n",
    "    df['FA_group']=''\n",
    "    df['LA_group']=''\n",
    "    ##Putting asian, hispanic and black authors in the nonwhite category 'N'\n",
    "    df['FA_group'].loc[df['FA_race'].isin(non_white)] = \"N\"\n",
    "    df['LA_group'].loc[df['LA_race'].isin(non_white)] = \"N\"\n",
    "\n",
    "    ## Putting white authors as white in grouping columns\n",
    "    df['FA_group'].loc[df['FA_race'] == 'W_NL'] = \"W\"\n",
    "    df['LA_group'].loc[df['LA_race'] == 'W_NL'] = \"W\"\n",
    "    \n",
    "    \n",
    "    ######## Repeating process for Ethnicolr results\n",
    "    df['FA_group_e']=''\n",
    "    df['LA_group_e']=''\n",
    "    df['FA_group_e'].loc[df['FA_ethni_race'].isin(non_white)] = \"N\"\n",
    "    df['LA_group_e'].loc[df['LA_ethni_race'].isin(non_white)] = \"N\"\n",
    "    df['FA_group_e'].loc[df['FA_ethni_race'] == 'W_NL'] = \"W\"\n",
    "    df['LA_group_e'].loc[df['LA_ethni_race'] == 'W_NL'] = \"W\"\n",
    "    df['FA_ethni_prop']=pd.to_numeric(df['FA_ethni_prop'], errors='coerce')\n",
    "    df['LA_ethni_prop']=pd.to_numeric(df['LA_ethni_prop'], errors='coerce')\n",
    "    \n",
    "    ####################### SIMPLIFYING NAMSOR GENDER RESULT #################\n",
    "    df['LA_gender']=df['LA_gender'].replace({'female':'W','male':'M'})\n",
    "    df['FA_gender']=df['FA_gender'].replace({'female':'W','male':'M'})\n",
    "\n",
    "    ############################## THRESHOLDING ############################\n",
    "    \n",
    "    df['FA_group_e'].loc[df['FA_ethni_prop']<threshold] = 'U'\n",
    "    df['FA_group_e'].loc[df['FA_ethni_prop'].isna()] = 'U'\n",
    "    df['LA_group_e'].loc[df['LA_ethni_prop']<threshold] = 'U'\n",
    "    df['LA_group_e'].loc[df['LA_ethni_prop'].isna()] = 'U'\n",
    "    df['groups_e']=df['FA_group_e']+df['LA_group_e']\n",
    "\n",
    "    df['FA_ethni_race'].loc[df['FA_ethni_prop']<threshold] = 'U'\n",
    "    df['LA_ethni_race'].loc[df['LA_ethni_prop']<threshold] = 'U'\n",
    "    df['FA_ethni_race'].loc[df['FA_ethni_prop'].isna()] = 'U'\n",
    "    df['LA_ethni_race'].loc[df['LA_ethni_prop'].isna()] = 'U'\n",
    "\n",
    "    df['FA_group'].loc[df['FA_prob_race']<threshold] = 'U'\n",
    "    df['LA_group'].loc[df['LA_prob_race']<threshold] = 'U'\n",
    "    df['FA_group'].loc[df['FA_prob_race'].isna()] = 'U'\n",
    "    df['LA_group'].loc[df['LA_prob_race'].isna()] = 'U'\n",
    "    df['groups']=df['FA_group']+df['LA_group']\n",
    "\n",
    "    df['FA_race'].loc[df['FA_prob_race']<threshold] = 'U'\n",
    "    df['LA_race'].loc[df['LA_prob_race']<threshold] = 'U'\n",
    "    df['FA_race'].loc[df['FA_prob_race'].isna()] = 'U'\n",
    "    df['LA_race'].loc[df['LA_prob_race'].isna()] = 'U'\n",
    "    \n",
    "    df['FA_gender'].loc[df['FA_prob_gender']<threshold] = 'U'\n",
    "    df['FA_gender'].loc[df['FA_prob_gender'].isna()] = 'U'\n",
    "    df['LA_gender'].loc[df['LA_prob_gender']<threshold] = 'U'\n",
    "    df['LA_gender'].loc[df['LA_prob_gender'].isna()] = 'U'\n",
    "    df['AG_namsor']=df['FA_gender']+df['LA_gender']\n",
    "    \n",
    "    \n",
    "    df['FA_group_g']='U'\n",
    "    df['FA_group_g'].loc[df['prob.w.fa']>=threshold]='W'\n",
    "    df['FA_group_g'].loc[df['prob.m.fa']>=threshold]='M'\n",
    "\n",
    "    df['LA_group_g']='U'\n",
    "    df['LA_group_g'].loc[df['prob.w.la']>=threshold]='W'\n",
    "    df['LA_group_g'].loc[df['prob.m.la']>=threshold]='M'\n",
    "    df['AG']=df['FA_group_g']+df['LA_group_g']\n",
    "    \n",
    "    #### SETTING PAPERS AS GLOBAL NORTH BASED ON LAST AUTHOR AFFILIATION\n",
    "   # definition of global north comes from:\n",
    "    # https://unctadstat.unctad.org/EN/Classifications/DimCountries_All_Hierarchy.pdf\n",
    "    westernworld=[ 'Bermuda','Canada','Greenland','USA','Cyprus','Israel','Australia',\n",
    "                  'Christmas Island','Cocos Island','Heard Island and McDonald Island','New Zealand',\n",
    "                  'Norfolk Island','United States Minor Outlying Islands','Aland Islands','Albania','Andorra',\n",
    "                  'Austria','Belarus','Belgium','Bosnia and Herzegovina','Bulgaria','Croatia','Czechia',\n",
    "                  'Czechoslovakia','Germany','Denmark','Estonia','Faroe Islands','Finland','France','Gibraltar',\n",
    "                 'Greece','Guernsey','Holy See','Hungary','Holy See','Hungary','Iceland','Ireland','Isle of Man',\n",
    "                 'Italy','Jersey','Kosovo','Latvia','Liechtenstein','Lithuania','Luxembourg','Malta','Monaco',\n",
    "                  'Montenegro','Netherlands','North Macedonia','Norway','Poland','Portugal',\n",
    "                  'Republic of Macedonia','Romania','Russia','San Marino','Serbia','Serbia and Montenegro',\n",
    "                 'Slovakia','Slovenia','Spain','Svalbard and Jan Mayen Islands','Sweden','Switzerland','Ukraine',\n",
    "                 'United Kingdom','Yugoslavia']\n",
    "    westernworld=[x.lower() for x in westernworld]\n",
    "    df_country=pd.read_csv(str(wd+'hc_authors.csv'))\n",
    "    df=pd.merge(df,df_country,how='left',on='UT')\n",
    "    \n",
    "    df['Country'] = df['Country'].str.lower()\n",
    "    ## Editing countries to correct names or update to new names\n",
    "    df['Country']=df['Country'].replace({'czech republic':'czechia','new caledonia':'france',\n",
    "                                         'england':'United Kingdom (Great Britain)',\n",
    "                                         'north ireland':'United Kingdom (Great Britain)',\n",
    "                                         'wales':'United Kingdom (Great Britain)',\n",
    "                                         'scotland':'United Kingdom (Great Britain)',\n",
    "                                        'french guiana':'France','u arab emirates':'UAE',\n",
    "                                        'dominican rep':'Dominican Republic',\n",
    "                                         'dem rep congo':'Democratic Republic of Congress',\n",
    "                                        'rep congo':'Republic of Congo','fed rep ger':'Germany',\n",
    "                                        'west germany':'Germany','austl.':'Australia',\n",
    "                                        'serbia monteneg':'Serbia and Montenegro','ussr':'Russia',\n",
    "                                         'cent afr republ':'Central African Republic',\n",
    "                                        'deutsch dem rep':'Germany','ger dem rep':'Germany',\n",
    "                                        'ukssr':'Ukraine','east germany':'Germany','united arab rep':'UAE',\n",
    "                                        'trin + tobago':'Trinidad and Tobago','trinidad tobago':'Trinidad and Tobago'})\n",
    "    \n",
    "    df['Country'] = df['Country'].str.lower()\n",
    "    df['global_north']=0\n",
    "    df['global_north'].loc[df['Country'].isin(westernworld)]=1\n",
    "\n",
    "    if dataset=='HC':\n",
    "        dataset='highlycited'\n",
    "    df.to_csv(\"/dworkin_code_api/\"+dataset+\"/df8_\"+dataset+\"_\"+str(threshold)+'.csv')\n",
    "\n",
    "thresholding(.7,'HC')\n",
    "thresholding(.6,'HC')\n",
    "thresholding(.8,'HC')\n",
    "thresholding(.7,'books')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29edf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac632e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
