{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119f2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ethnicolr as ec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pypopulation\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import statistics\n",
    "import statistics\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import os \n",
    "os.chdir(\"/Users/alexesmerritt/Library/CloudStorage/GoogleDrive-akm147@georgetown.edu/My Drive/citation_bias/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01df84e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF</th>\n",
       "      <th>SO</th>\n",
       "      <th>DI</th>\n",
       "      <th>PY</th>\n",
       "      <th>PD</th>\n",
       "      <th>DT</th>\n",
       "      <th>WC</th>\n",
       "      <th>UT</th>\n",
       "      <th>TC</th>\n",
       "      <th>PM</th>\n",
       "      <th>...</th>\n",
       "      <th>LA_gender</th>\n",
       "      <th>LA_prob_gender</th>\n",
       "      <th>FA_race2</th>\n",
       "      <th>FA_race</th>\n",
       "      <th>FA_prob_race</th>\n",
       "      <th>FA_prob2</th>\n",
       "      <th>LA_race2</th>\n",
       "      <th>LA_race</th>\n",
       "      <th>LA_prob_race</th>\n",
       "      <th>LA_prob2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pastor-Satorras, Romualdo; Castellano, Claudio...</td>\n",
       "      <td>REVIEWS OF MODERN PHYSICS</td>\n",
       "      <td>10.1103/revmodphys.87.925</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Article</td>\n",
       "      <td>Physics, Multidisciplinary</td>\n",
       "      <td>WOS:000360273200001</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>0.849541</td>\n",
       "      <td>A</td>\n",
       "      <td>HL</td>\n",
       "      <td>0.933615</td>\n",
       "      <td>0.971699</td>\n",
       "      <td>HL</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.728010</td>\n",
       "      <td>0.913238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brockmann, Dirk; Helbing, Dirk</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>10.1126/science.1245200</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Article</td>\n",
       "      <td>Multidisciplinary Sciences</td>\n",
       "      <td>WOS:000328196000041</td>\n",
       "      <td>847.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>0.885795</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.944775</td>\n",
       "      <td>0.987782</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.944766</td>\n",
       "      <td>0.978747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cori, Anne; Ferguson, Neil Morris; Fraser, Chr...</td>\n",
       "      <td>AMERICAN JOURNAL OF EPIDEMIOLOGY</td>\n",
       "      <td>10.1093/aje/kwt133</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Article</td>\n",
       "      <td>Public, Environmental &amp; Occupational Health</td>\n",
       "      <td>WOS:000326642300019</td>\n",
       "      <td>629.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>0.924955</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.920133</td>\n",
       "      <td>0.949379</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>HL</td>\n",
       "      <td>0.544719</td>\n",
       "      <td>0.805079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Granell, Clara; Gomez, Sergio Yebrail; Arenas,...</td>\n",
       "      <td>PHYSICAL REVIEW LETTERS</td>\n",
       "      <td>10.1103/physrevlett.111.128701</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Article</td>\n",
       "      <td>Physics, Multidisciplinary</td>\n",
       "      <td>WOS:000324489200024</td>\n",
       "      <td>748.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>0.915548</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>HL</td>\n",
       "      <td>0.512174</td>\n",
       "      <td>0.755726</td>\n",
       "      <td>A</td>\n",
       "      <td>HL</td>\n",
       "      <td>0.950780</td>\n",
       "      <td>0.979853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Funk, Sebastian; Salathe, Marcel; Jansen, Vinc...</td>\n",
       "      <td>JOURNAL OF THE ROYAL SOCIETY INTERFACE</td>\n",
       "      <td>10.1098/rsif.2010.0142</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Review</td>\n",
       "      <td>Multidisciplinary Sciences</td>\n",
       "      <td>WOS:000280332700001</td>\n",
       "      <td>821.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>0.808029</td>\n",
       "      <td>HL</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.716619</td>\n",
       "      <td>0.941444</td>\n",
       "      <td>A</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.940211</td>\n",
       "      <td>0.967272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243079</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WOS:A1971I834300001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>0.919714</td>\n",
       "      <td>HL</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.701734</td>\n",
       "      <td>0.877956</td>\n",
       "      <td>HL</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.701734</td>\n",
       "      <td>0.877956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243080</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WOS:A1970F007100047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>0.537078</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.711735</td>\n",
       "      <td>0.878618</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.567341</td>\n",
       "      <td>0.776085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243081</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WOS:A1977DP97400004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>0.704495</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.750020</td>\n",
       "      <td>0.956163</td>\n",
       "      <td>A</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>0.562326</td>\n",
       "      <td>0.743506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243082</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WOS:A1976BZ81400002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>male</td>\n",
       "      <td>0.960273</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>0.784284</td>\n",
       "      <td>0.979746</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>0.784284</td>\n",
       "      <td>0.979746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243083</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WOS:A1971K360700002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>0.859309</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>0.456670</td>\n",
       "      <td>0.970892</td>\n",
       "      <td>W_NL</td>\n",
       "      <td>B_NL</td>\n",
       "      <td>0.456670</td>\n",
       "      <td>0.970892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216912 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       AF  \\\n",
       "0       Pastor-Satorras, Romualdo; Castellano, Claudio...   \n",
       "1                          Brockmann, Dirk; Helbing, Dirk   \n",
       "2       Cori, Anne; Ferguson, Neil Morris; Fraser, Chr...   \n",
       "3       Granell, Clara; Gomez, Sergio Yebrail; Arenas,...   \n",
       "4       Funk, Sebastian; Salathe, Marcel; Jansen, Vinc...   \n",
       "...                                                   ...   \n",
       "243079                                                NaN   \n",
       "243080                                                NaN   \n",
       "243081                                                NaN   \n",
       "243082                                                NaN   \n",
       "243083                                                NaN   \n",
       "\n",
       "                                            SO  \\\n",
       "0                    REVIEWS OF MODERN PHYSICS   \n",
       "1                                      SCIENCE   \n",
       "2             AMERICAN JOURNAL OF EPIDEMIOLOGY   \n",
       "3                      PHYSICAL REVIEW LETTERS   \n",
       "4       JOURNAL OF THE ROYAL SOCIETY INTERFACE   \n",
       "...                                        ...   \n",
       "243079                                     NaN   \n",
       "243080                                     NaN   \n",
       "243081                                     NaN   \n",
       "243082                                     NaN   \n",
       "243083                                     NaN   \n",
       "\n",
       "                                    DI      PY    PD       DT  \\\n",
       "0            10.1103/revmodphys.87.925  2015.0   8.0  Article   \n",
       "1              10.1126/science.1245200  2013.0  12.0  Article   \n",
       "2                   10.1093/aje/kwt133  2013.0  11.0  Article   \n",
       "3       10.1103/physrevlett.111.128701  2013.0   9.0  Article   \n",
       "4               10.1098/rsif.2010.0142  2010.0   9.0   Review   \n",
       "...                                ...     ...   ...      ...   \n",
       "243079                             NaN     NaN   NaN      NaN   \n",
       "243080                             NaN     NaN   NaN      NaN   \n",
       "243081                             NaN     NaN   NaN      NaN   \n",
       "243082                             NaN     NaN   NaN      NaN   \n",
       "243083                             NaN     NaN   NaN      NaN   \n",
       "\n",
       "                                                 WC                   UT  \\\n",
       "0                        Physics, Multidisciplinary  WOS:000360273200001   \n",
       "1                        Multidisciplinary Sciences  WOS:000328196000041   \n",
       "2       Public, Environmental & Occupational Health  WOS:000326642300019   \n",
       "3                        Physics, Multidisciplinary  WOS:000324489200024   \n",
       "4                        Multidisciplinary Sciences  WOS:000280332700001   \n",
       "...                                             ...                  ...   \n",
       "243079                                          NaN  WOS:A1971I834300001   \n",
       "243080                                          NaN  WOS:A1970F007100047   \n",
       "243081                                          NaN  WOS:A1977DP97400004   \n",
       "243082                                          NaN  WOS:A1976BZ81400002   \n",
       "243083                                          NaN  WOS:A1971K360700002   \n",
       "\n",
       "            TC  PM  ... LA_gender  LA_prob_gender FA_race2 FA_race  \\\n",
       "0       2401.0 NaN  ...      male        0.849541        A      HL   \n",
       "1        847.0 NaN  ...      male        0.885795     B_NL    W_NL   \n",
       "2        629.0 NaN  ...      male        0.924955     B_NL    W_NL   \n",
       "3        748.0 NaN  ...      male        0.915548     B_NL      HL   \n",
       "4        821.0 NaN  ...      male        0.808029       HL    W_NL   \n",
       "...        ...  ..  ...       ...             ...      ...     ...   \n",
       "243079     NaN NaN  ...      male        0.919714       HL    W_NL   \n",
       "243080     NaN NaN  ...      male        0.537078     B_NL    W_NL   \n",
       "243081     NaN NaN  ...      male        0.704495     B_NL    W_NL   \n",
       "243082     NaN NaN  ...      male        0.960273     W_NL    B_NL   \n",
       "243083     NaN NaN  ...    female        0.859309     W_NL    B_NL   \n",
       "\n",
       "        FA_prob_race  FA_prob2  LA_race2  LA_race LA_prob_race  LA_prob2  \n",
       "0           0.933615  0.971699        HL     W_NL     0.728010  0.913238  \n",
       "1           0.944775  0.987782      B_NL     W_NL     0.944766  0.978747  \n",
       "2           0.920133  0.949379      W_NL       HL     0.544719  0.805079  \n",
       "3           0.512174  0.755726         A       HL     0.950780  0.979853  \n",
       "4           0.716619  0.941444         A     W_NL     0.940211  0.967272  \n",
       "...              ...       ...       ...      ...          ...       ...  \n",
       "243079      0.701734  0.877956        HL     W_NL     0.701734  0.877956  \n",
       "243080      0.711735  0.878618      B_NL     W_NL     0.567341  0.776085  \n",
       "243081      0.750020  0.956163         A     W_NL     0.562326  0.743506  \n",
       "243082      0.784284  0.979746      W_NL     B_NL     0.784284  0.979746  \n",
       "243083      0.456670  0.970892      W_NL     B_NL     0.456670  0.970892  \n",
       "\n",
       "[216912 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################### READING IN RESULTS FROM NAMSOR AND STEP 7 ####################################\n",
    "\n",
    "df0 = pd.read_csv(\"dworkin_code_api/coreidd/df7_articledata_withgenders.csv\")\n",
    "\n",
    "      \n",
    "# FIRST AUTHOR GENDER FILES\n",
    "df_FAgender=pd.read_csv('namsor_inputs/namsor_genderize-full-name_highlycited_processed_namsor_input.csv')\n",
    "df_FAgender=df_FAgender.rename(columns={'likelyGender':'FA_gender', 'probabilityCalibrated':'FA_prob_gender'})\n",
    "df_FAgender=df_FAgender[['UT','FA_gender', 'FA_prob_gender']]\n",
    "\n",
    "# LAST AUTHOR GENDER FILES\n",
    "df_LAgender=pd.read_csv('namsor_inputs/namsor_genderize-full-name_highlycited_processed_namsor_input (1).csv')\n",
    "df_LAgender=df_LAgender.rename(columns={'likelyGender':'LA_gender', 'probabilityCalibrated':'LA_prob_gender'})\n",
    "df_LAgender=df_LAgender[['UT','LA_gender', 'LA_prob_gender']]\n",
    "\n",
    "df0=df0.merge(df_FAgender,on='UT',how='outer')\n",
    "df0=df0.merge(df_LAgender,on='UT',how='outer')\n",
    "\n",
    "# FIRST AUTHOR RACE FILES\n",
    "df_FArace=pd.read_csv('namsor_inputs/namsor_full-name-us-race_highlycited_processed_namsor_input.csv')\n",
    "df_FArace=df_FArace.rename(columns={'raceEthnicityAlt':'FA_race2', 'raceEthnicity':'FA_race',\n",
    "                                    'probabilityCalibrated':'FA_prob_race','probabilityAltCalibrated':'FA_prob2'})\n",
    "df_FArace=df_FArace[['UT','FA_race2', 'FA_race', 'FA_prob_race', 'FA_prob2']]\n",
    "\n",
    "      \n",
    "# LAST AUTHOR RACE FILES\n",
    "df_LArace=pd.read_csv('namsor_inputs/namsor_full-name-us-race_highlycited_processed_namsor_input (1).csv')\n",
    "df_LArace=df_LArace.rename(columns={'raceEthnicityAlt':'LA_race2', 'raceEthnicity':'LA_race',\n",
    "                                    'probabilityCalibrated':'LA_prob_race','probabilityAltCalibrated':'LA_prob2'})\n",
    "df_LArace=df_LArace[['UT','LA_race2', 'LA_race', 'LA_prob_race', 'LA_prob2']]\n",
    "###ALL DATA IN ONE FILE\n",
    "df0=df0.merge(df_FArace,on='UT',how='outer')\n",
    "df0=df0.merge(df_LArace,on='UT',how='outer')\n",
    "\n",
    "df0.loc[~df0['FA_race'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da5ebea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bi, Jichao' 'Zhou, Yingjie' 'Song, Yutong' ... 'STROBEL, Gary A.'\n",
      " 'FELLOUS, Marc' 'COLE, Tim J.']\n"
     ]
    }
   ],
   "source": [
    "df=df0\n",
    "####################### ORGANIZING AUTHOR FIRST AND LAST NAME FOR ETHNICOLR ##################################\n",
    "df['first_auth'] = df['first_auth'].astype(str)\n",
    "df['last_auth'] = df['last_auth'].astype(str)\n",
    "FAl=list(df['first_auth'])\n",
    "LAl=list(df['last_auth'])\n",
    "\n",
    "df['FAFN']=''\n",
    "df['FALN']=''\n",
    "df['LAFN']=''\n",
    "df['LALN']=''\n",
    "FAFN=list(df['FAFN'])\n",
    "FALN=list(df['FALN'])\n",
    "LAFN=list(df['LAFN'])\n",
    "LALN=list(df['LALN'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(df)): \n",
    "    if ', ' in LAl[i]:\n",
    "        LA=LAl[i].split(', ')\n",
    "        LAl[i]=LA[1]+' '+LA[0]\n",
    "        LAFN[i]=LA[1]\n",
    "        LALN[i]=LA[0]\n",
    "    if ', ' in FAl[i]:\n",
    "        FA=FAl[i].split(', ')\n",
    "        FAl[i]=FA[1]+' '+LA[0]\n",
    "        FAFN[i]=FA[1]\n",
    "        FALN[i]=FA[0]\n",
    "\n",
    "df['FAFN']=FAFN\n",
    "df['FALN']=FALN\n",
    "df['LAFN']=LAFN\n",
    "df['LALN']=LALN\n",
    "        \n",
    "df['FAFN']=df['FAFN'].str.title()\n",
    "df['FALN']=df['FALN'].str.title()\n",
    "df['LAFN']=df['LAFN'].str.title()\n",
    "df['LALN']=df['LALN'].str.title()\n",
    "print(df['first_auth'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a3b9304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160228"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"dworkin_code_api/coreidd/namsor_completed_df7.5.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d103065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you will see a series of runs of the same program, ethnicolr times out and had problems with large datasets.\n",
    "### To work around this we ran the datasets and then find which names it wasnt able to produce a prediction for.\n",
    "### Getting this took us 4 rounds of ethnicolr.\n",
    "\n",
    "#Creating Dataframes\n",
    "df_LA=df[['UT','LALN','LAFN']]\n",
    "df_FA=df[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 1 FA\n",
    "results_FA = ec.pred_fl_reg_name(df_FA, 'FALN', 'FAFN')\n",
    "results_FA=results_FA.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 1 LA\n",
    "results_LA = ec.pred_fl_reg_name(df_LA, 'LALN', 'LAFN')\n",
    "results_LA=results_LA.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37bc9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 2\n",
    "\n",
    "#Finding Nan Papers\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "#Making Datasets\n",
    "\n",
    "df_FA_nan=df.loc[df['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df.loc[df['UT'].isin(UT_LA_nan)]\n",
    "\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 2 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 2 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e3c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Ethnicolr 1 and 2\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534fdebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 3\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df.loc[df['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df.loc[df['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 3 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 3 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39481eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Results from 1&2 with 3\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e993605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 4\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df.loc[df['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df.loc[df['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 4 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 4 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46ec21be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hispanic' 'nh_white' 'nh_black' 'asian' nan]\n",
      "Index(['Unnamed: 0', 'AF', 'SO', 'DI', 'PY', 'PD', 'DT', 'WC', 'UT', 'TC',\n",
      "       'PM', 'TI', 'done', 'fa_fname', 'la_fname', 'prob.m.fa', 'prob.w.fa',\n",
      "       'prob.m.la', 'prob.w.la', 'first_auth', 'last_auth', 'FALN', 'FAFN',\n",
      "       'LALN', 'LAFN', 'FA_race', 'FA_prob_race', 'LA_race', 'LA_prob_race',\n",
      "       'FA_gender', 'FA_prob_gender', 'LA_gender', 'LA_prob_gender',\n",
      "       'FA_ethni_race', 'LA_ethni_race', 'FA_ethni_prop', 'LA_ethni_prop'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m df_comp\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlexes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Section/Prethresholding_HC.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m df_UT\u001b[38;5;241m=\u001b[39mdf_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 35\u001b[0m df_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_' is not defined"
     ]
    }
   ],
   "source": [
    "#Merging Results from 1,2,3 with 4\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "results=results_LA.merge(results_FA,on='UT',how='outer')\n",
    "\n",
    "results['LA_ethni_prop']=''\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='asian']=results['LA_asian'].loc[results['LA_ethni_race']=='asian']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_white']=results['LA_white'].loc[results['LA_ethni_race']=='nh_white']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='hispanic']=results['LA_hispanic'].loc[results['LA_ethni_race']=='hispanic']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_black']=results['LA_black'].loc[results['LA_ethni_race']=='nh_black']\n",
    "\n",
    "results['FA_ethni_prop']=''\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='asian']=results['FA_asian'].loc[results['FA_ethni_race']=='asian']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_white']=results['FA_white'].loc[results['FA_ethni_race']=='nh_white']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='hispanic']=results['FA_hispanic'].loc[results['FA_ethni_race']=='hispanic']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_black']=results['FA_black'].loc[results['FA_ethni_race']=='nh_black']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(results['FA_ethni_race'].unique())\n",
    "\n",
    "results=results[['UT','FA_ethni_race','LA_ethni_race','FA_ethni_prop','LA_ethni_prop']]\n",
    "df_comp=df.merge(results,on='UT',how='outer')\n",
    "df_comp=df_comp.replace({'nh_white':'W_NL', 'asian':'A', 'hispanic':\"HL\", 'nh_black':'B_NL'})\n",
    "\n",
    "df_comp=df_comp.rename(columns={'LA_race_prob':'LA_prob_race','FA_race_prob':'FA_prob_race'})\n",
    "df_comp=df_comp.rename(columns={'LA_gender_prob':'LA_prob_gender','FA_gender_prob':'FA_prob_gender'})\n",
    "print(df_comp.columns)\n",
    "df_comp.to_csv(\"Alexes' Section/Prethresholding_HC.csv\")\n",
    "\n",
    "# Outputing a file that has results for the papers wherever possible and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd18ee1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_comp=pd.read_csv(\"Alexes' Section/Prethresholding_HC.csv\")\n",
    "df_UT=df_comp[['UT']]\n",
    "print(len(df_comp.loc[df_comp['UT'].isna()]))\n",
    "\n",
    "df_UT['UT']=df_UT['UT'].str.replace('WOS', 'UT', regex=True)\n",
    "print(len(df_UT.loc[df_UT['UT'].isna()]))\n",
    "df_UT['UT'].to_csv(\"Alexes' Section/HC_UT.txt\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e9956",
   "metadata": {},
   "source": [
    "# Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d774b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############REPEATING ALL THE PREVIOUS STEPS FOR OUR DEFINITION OF THE FIELD BASED ON BOOKS.\n",
    "df0 = pd.read_csv(\"/dworkin_code_api/books/df7_articledata_withgenders.csv\")\n",
    "\n",
    "df_FAgender=pd.read_csv('/namsor_inputs/namsor_genderize-full-name_books_processed_namsor_input.csv')\n",
    "df_FAgender=df_FAgender.rename(columns={'likelyGender':'FA_gender', 'probabilityCalibrated':'FA_prob_gender'})\n",
    "df_FAgender=df_FAgender[['UT','FA_gender', 'FA_prob_gender']]\n",
    "\n",
    "df_LAgender=pd.read_csv('/namsor_inputs/namsor_genderize-full-name_books_processed_namsor_input (1).csv')\n",
    "df_LAgender=df_LAgender.rename(columns={'likelyGender':'LA_gender', 'probabilityCalibrated':'LA_prob_gender'})\n",
    "df_LAgender=df_LAgender[['UT','LA_gender', 'LA_prob_gender']]\n",
    "\n",
    "df0=df0.merge(df_FAgender,on='UT',how='outer')\n",
    "df0=df0.merge(df_LAgender,on='UT',how='outer')\n",
    "\n",
    "df_FArace=pd.read_csv('/namsor_inputs/namsor_full-name-us-race_books_processed_namsor_input.csv')\n",
    "df_FArace=df_FArace.rename(columns={'raceEthnicityAlt':'FA_race2', 'raceEthnicity':'FA_race',\n",
    "                                    'probabilityCalibrated':'FA_prob_race','probabilityAltCalibrated':'FA_prob2'})\n",
    "df_FArace=df_FArace[['UT','FA_race2', 'FA_race', 'FA_prob_race', 'FA_prob2']]\n",
    "\n",
    "df_LArace=pd.read_csv('/namsor_inputs/namsor_full-name-us-race_books_processed_namsor_input (1).csv')\n",
    "df_LArace=df_LArace.rename(columns={'raceEthnicityAlt':'LA_race2', 'raceEthnicity':'LA_race',\n",
    "                                    'probabilityCalibrated':'LA_prob_race','probabilityAltCalibrated':'LA_prob2'})\n",
    "df_LArace=df_LArace[['UT','LA_race2', 'LA_race', 'LA_prob_race', 'LA_prob2']]\n",
    "\n",
    "df0=df0.merge(df_FArace,on='UT',how='outer')\n",
    "df0=df0.merge(df_LArace,on='UT',how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224570ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kabir, M. Humayun' 'Elsadany, A. A.' 'Igoe, Morganne' ...\n",
      " 'MITSUYA, Hiroaki' 'NEEQUAYE, AR' 'BELSEY, MA']\n"
     ]
    }
   ],
   "source": [
    "df=df0\n",
    "\n",
    "df['first_auth'] = df['first_auth'].astype(str)\n",
    "df['last_auth'] = df['last_auth'].astype(str)\n",
    "FAl=list(df['first_auth'])\n",
    "LAl=list(df['last_auth'])\n",
    "\n",
    "df['FAFN']=''\n",
    "df['FALN']=''\n",
    "df['LAFN']=''\n",
    "df['LALN']=''\n",
    "FAFN=list(df['FAFN'])\n",
    "FALN=list(df['FALN'])\n",
    "LAFN=list(df['LAFN'])\n",
    "LALN=list(df['LALN'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(df)): \n",
    "    if ', ' in LAl[i]:\n",
    "        LA=LAl[i].split(', ')\n",
    "        LAl[i]=LA[1]+' '+LA[0]\n",
    "        LAFN[i]=LA[1]\n",
    "        LALN[i]=LA[0]\n",
    "    if ', ' in FAl[i]:\n",
    "        FA=FAl[i].split(', ')\n",
    "        FAl[i]=FA[1]+' '+LA[0]\n",
    "        FAFN[i]=FA[1]\n",
    "        FALN[i]=FA[0]\n",
    "\n",
    "df['FAFN']=FAFN\n",
    "df['FALN']=FALN\n",
    "df['LAFN']=LAFN\n",
    "df['LALN']=LALN\n",
    "        \n",
    "df['FAFN']=df['FAFN'].str.title()\n",
    "df['FALN']=df['FALN'].str.title()\n",
    "df['LAFN']=df['LAFN'].str.title()\n",
    "df['LALN']=df['LALN'].str.title()\n",
    "print(df['first_auth'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Run of Ethnicolr\n",
    "\n",
    "#Creating Dataframes\n",
    "df_LA=df[['UT','LALN','LAFN']]\n",
    "df_FA=df[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 1 FA\n",
    "results_FA = ec.pred_fl_reg_name(df_FA, 'FALN', 'FAFN')\n",
    "results_FA=results_FA.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 1 LA\n",
    "results_LA = ec.pred_fl_reg_name(df_LA, 'LALN', 'LAFN')\n",
    "results_LA=results_LA.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38106d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 2\n",
    "\n",
    "#Finding Nan Papers\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "#Making Datasets\n",
    "\n",
    "df_FA_nan=df.loc[df['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df.loc[df['UT'].isin(UT_LA_nan)]\n",
    "\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "#Ethnicolr 2 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "#Ethnicolr 2 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Ethnicolr 1 and 2\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 3\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df0.loc[df0['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df0.loc[df0['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 3 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 3 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Results from 1&2 with 3\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicolr 4\n",
    "UT_FA_nan=main_list = list(set(df['UT']) - set(results_FA['UT']))\n",
    "\n",
    "UT_LA_nan=main_list = list(set(df['UT']) - set(results_LA['UT']))\n",
    "\n",
    "df_FA_nan=df0.loc[df0['UT'].isin(UT_FA_nan)]\n",
    "\n",
    "df_LA_nan=df0.loc[df0['UT'].isin(UT_LA_nan)]\n",
    "#Make Data Frames\n",
    "df_LA_nan=df_LA_nan[['UT','LALN','LAFN']]\n",
    "df_FA_nan=df_FA_nan[['UT','FALN', 'FAFN']]\n",
    "\n",
    "\n",
    "#Ethnicolr 4 FA\n",
    "results_FA_nan = ec.pred_fl_reg_name(df_FA_nan, 'FALN', 'FAFN')\n",
    "results_FA_nan=results_FA_nan.rename(columns={'asian':'FA_asian', 'hispanic':'FA_hispanic', 'nh_black':'FA_black',\n",
    "       'nh_white':'FA_white', 'race':'FA_ethni_race'})\n",
    "\n",
    "#Ethniclor 4 LA\n",
    "results_LA_nan = ec.pred_fl_reg_name(df_LA_nan, 'LALN', 'LAFN')\n",
    "results_LA_nan=results_LA_nan.rename(columns={'asian':'LA_asian', 'hispanic':'LA_hispanic', 'nh_black':'LA_black',\n",
    "       'nh_white':'LA_white', 'race':'LA_ethni_race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3839781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Results from 1,2,3 with 4\n",
    "results_FA=pd.concat([results_FA,results_FA_nan],ignore_index=True)\n",
    "results_LA=pd.concat([results_LA,results_LA_nan],ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "results=results_LA.merge(results_FA,on='UT',how='outer')\n",
    "\n",
    "results['LA_ethni_prop']=''\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='asian']=results['LA_asian'].loc[results['LA_ethni_race']=='asian']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_white']=results['LA_white'].loc[results['LA_ethni_race']=='nh_white']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='hispanic']=results['LA_hispanic'].loc[results['LA_ethni_race']=='hispanic']\n",
    "results['LA_ethni_prop'].loc[results['LA_ethni_race']=='nh_black']=results['LA_black'].loc[results['LA_ethni_race']=='nh_black']\n",
    "\n",
    "results['FA_ethni_prop']=''\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='asian']=results['FA_asian'].loc[results['FA_ethni_race']=='asian']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_white']=results['FA_white'].loc[results['FA_ethni_race']=='nh_white']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='hispanic']=results['FA_hispanic'].loc[results['FA_ethni_race']=='hispanic']\n",
    "results['FA_ethni_prop'].loc[results['FA_ethni_race']=='nh_black']=results['FA_black'].loc[results['FA_ethni_race']=='nh_black']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(results['FA_ethni_race'].unique())\n",
    "\n",
    "results=results[['UT','FA_ethni_race','LA_ethni_race','FA_ethni_prop','LA_ethni_prop']]\n",
    "df_comp=df.merge(results,on='UT',how='outer')\n",
    "df_comp=df_comp.replace({'nh_white':'W_NL', 'asian':'A', 'hispanic':\"HL\", 'nh_black':'B_NL'})\n",
    "df_comp.to_csv(\"Alexes' Section/Prethresholding_books.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63f06d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_comp=pd.read_csv(\"Alexes' Section/Prethresholding_books.csv\")\n",
    "df_UT=df_comp[['UT']]\n",
    "df_UT['UT']=df_UT['UT'].str.replace('WOS', 'UT', regex=True)\n",
    "df_UT['UT'].to_csv(\"Alexes' Section/books_UT.txt\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b444611",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8751f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUnction that will group and threshold different any of the datasets\n",
    "\"/Users/alexesmerritt/Library/CloudStorage/GoogleDrive-akm147@georgetown.edu/My Drive/citation_bias/\"\n",
    "def thresholding(threshold,dataset):\n",
    "    df=pd.read_csv(\"Alexes' Section/Prethresholding_\"+dataset+\".csv\")\n",
    "    ########################### THRESHOLDING FOR RACE ###########################\n",
    "    non_white =['A', 'HL', 'B_NL']\n",
    "    ######## Grouping namsore Race outputs\n",
    "    #creating column to save output\n",
    "    df['FA_group']=''\n",
    "    df['LA_group']=''\n",
    "    ##Putting asian, hispanic and black authors in the nonwhite category 'N'\n",
    "    df['FA_group'].loc[df['FA_race'].isin(non_white)] = \"N\"\n",
    "    df['LA_group'].loc[df['LA_race'].isin(non_white)] = \"N\"\n",
    "\n",
    "    ## Putting white authors as white in grouping columns\n",
    "    df['FA_group'].loc[df['FA_race'] == 'W_NL'] = \"W\"\n",
    "    df['LA_group'].loc[df['LA_race'] == 'W_NL'] = \"W\"\n",
    "    \n",
    "    \n",
    "    ######## Repeating process for Ethnicolr results\n",
    "    df['FA_group_e']=''\n",
    "    df['LA_group_e']=''\n",
    "    df['FA_group_e'].loc[df['FA_ethni_race'].isin(non_white)] = \"N\"\n",
    "    df['LA_group_e'].loc[df['LA_ethni_race'].isin(non_white)] = \"N\"\n",
    "    df['FA_group_e'].loc[df['FA_ethni_race'] == 'W_NL'] = \"W\"\n",
    "    df['LA_group_e'].loc[df['LA_ethni_race'] == 'W_NL'] = \"W\"\n",
    "    df['FA_ethni_prop']=pd.to_numeric(df['FA_ethni_prop'], errors='coerce')\n",
    "    df['LA_ethni_prop']=pd.to_numeric(df['LA_ethni_prop'], errors='coerce')\n",
    "    \n",
    "    ####################### SIMPLIFYING NAMSOR GENDER RESULT #################\n",
    "    df['LA_gender']=df['LA_gender'].replace({'female':'W','male':'M'})\n",
    "    df['FA_gender']=df['FA_gender'].replace({'female':'W','male':'M'})\n",
    "\n",
    "    ############################## THRESHOLDING ############################\n",
    "    \n",
    "    df['FA_group_e'].loc[df['FA_ethni_prop']<threshold] = 'U'\n",
    "    df['FA_group_e'].loc[df['FA_ethni_prop'].isna()] = 'U'\n",
    "    df['LA_group_e'].loc[df['LA_ethni_prop']<threshold] = 'U'\n",
    "    df['LA_group_e'].loc[df['LA_ethni_prop'].isna()] = 'U'\n",
    "    df['groups_e']=df['FA_group_e']+df['LA_group_e']\n",
    "\n",
    "    df['FA_ethni_race'].loc[df['FA_ethni_prop']<threshold] = 'U'\n",
    "    df['LA_ethni_race'].loc[df['LA_ethni_prop']<threshold] = 'U'\n",
    "    df['FA_ethni_race'].loc[df['FA_ethni_prop'].isna()] = 'U'\n",
    "    df['LA_ethni_race'].loc[df['LA_ethni_prop'].isna()] = 'U'\n",
    "\n",
    "    df['FA_group'].loc[df['FA_prob_race']<threshold] = 'U'\n",
    "    df['LA_group'].loc[df['LA_prob_race']<threshold] = 'U'\n",
    "    df['FA_group'].loc[df['FA_prob_race'].isna()] = 'U'\n",
    "    df['LA_group'].loc[df['LA_prob_race'].isna()] = 'U'\n",
    "    df['groups']=df['FA_group']+df['LA_group']\n",
    "\n",
    "    df['FA_race'].loc[df['FA_prob_race']<threshold] = 'U'\n",
    "    df['LA_race'].loc[df['LA_prob_race']<threshold] = 'U'\n",
    "    df['FA_race'].loc[df['FA_prob_race'].isna()] = 'U'\n",
    "    df['LA_race'].loc[df['LA_prob_race'].isna()] = 'U'\n",
    "    \n",
    "    df['FA_gender'].loc[df['FA_prob_gender']<threshold] = 'U'\n",
    "    df['FA_gender'].loc[df['FA_prob_gender'].isna()] = 'U'\n",
    "    df['LA_gender'].loc[df['LA_prob_gender']<threshold] = 'U'\n",
    "    df['LA_gender'].loc[df['LA_prob_gender'].isna()] = 'U'\n",
    "    df['AG_namsor']=df['FA_gender']+df['LA_gender']\n",
    "    \n",
    "    \n",
    "    df['FA_group_g']='U'\n",
    "    df['FA_group_g'].loc[df['prob.w.fa']>=threshold]='W'\n",
    "    df['FA_group_g'].loc[df['prob.m.fa']>=threshold]='M'\n",
    "\n",
    "    df['LA_group_g']='U'\n",
    "    df['LA_group_g'].loc[df['prob.w.la']>=threshold]='W'\n",
    "    df['LA_group_g'].loc[df['prob.m.la']>=threshold]='M'\n",
    "    df['AG']=df['FA_group_g']+df['LA_group_g']\n",
    "    \n",
    "    #### SETTING PAPERS AS GLOBAL NORTH BASED ON LAST AUTHOR AFFILIATION\n",
    "   # definition of global north comes from:\n",
    "    # https://unctadstat.unctad.org/EN/Classifications/DimCountries_All_Hierarchy.pdf\n",
    "    westernworld=[ 'Bermuda','Canada','Greenland','USA','Cyprus','Israel','Australia',\n",
    "                  'Christmas Island','Cocos Island','Heard Island and McDonald Island','New Zealand',\n",
    "                  'Norfolk Island','United States Minor Outlying Islands','Aland Islands','Albania','Andorra',\n",
    "                  'Austria','Belarus','Belgium','Bosnia and Herzegovina','Bulgaria','Croatia','Czechia',\n",
    "                  'Czechoslovakia','Germany','Denmark','Estonia','Faroe Islands','Finland','France','Gibraltar',\n",
    "                 'Greece','Guernsey','Holy See','Hungary','Holy See','Hungary','Iceland','Ireland','Isle of Man',\n",
    "                 'Italy','Jersey','Kosovo','Latvia','Liechtenstein','Lithuania','Luxembourg','Malta','Monaco',\n",
    "                  'Montenegro','Netherlands','North Macedonia','Norway','Poland','Portugal',\n",
    "                  'Republic of Macedonia','Romania','Russia','San Marino','Serbia','Serbia and Montenegro',\n",
    "                 'Slovakia','Slovenia','Spain','Svalbard and Jan Mayen Islands','Sweden','Switzerland','Ukraine',\n",
    "                 'United Kingdom','Yugoslavia']\n",
    "    westernworld=[x.lower() for x in westernworld]\n",
    "    if dataset=='HC':\n",
    "        df_country=pd.read_csv(\"Alexes' Section/coreidd_exporter/HC_countries.csv\")\n",
    "    elif dataset=='books':\n",
    "        df_country=pd.read_csv(\"Alexes' Section/coreidd_exporter/books_countries.csv\")\n",
    "        \n",
    "    df_country=df_country.rename(columns={'Accession Number (UT)':'UT'})\n",
    "    df_country=df_country[['UT','Country','Researcher/Author SeqNo (position)']]\n",
    "    df_country=df_country.sort_values(by=['UT','Researcher/Author SeqNo (position)']).drop_duplicates(subset=['UT'],keep='last')\n",
    "    df_country=df_country[['UT','Country']]\n",
    "    df=pd.merge(df,df_country,how='left',on='UT')\n",
    "    \n",
    "    df['Country'] = df['Country'].str.lower()\n",
    "    ## Editing countries to correct names or update to new names\n",
    "    df['Country']=df['Country'].replace({'czech republic':'czechia','new caledonia':'france',\n",
    "                                         'england':'United Kingdom (Great Britain)',\n",
    "                                         'north ireland':'United Kingdom (Great Britain)',\n",
    "                                         'wales':'United Kingdom (Great Britain)',\n",
    "                                         'scotland':'United Kingdom (Great Britain)',\n",
    "                                        'french guiana':'France','u arab emirates':'UAE',\n",
    "                                        'dominican rep':'Dominican Republic',\n",
    "                                         'dem rep congo':'Democratic Republic of Congress',\n",
    "                                        'rep congo':'Republic of Congo','fed rep ger':'Germany',\n",
    "                                        'west germany':'Germany','austl.':'Australia',\n",
    "                                        'serbia monteneg':'Serbia and Montenegro','ussr':'Russia',\n",
    "                                         'cent afr republ':'Central African Republic',\n",
    "                                        'deutsch dem rep':'Germany','ger dem rep':'Germany',\n",
    "                                        'ukssr':'Ukraine','east germany':'Germany','united arab rep':'UAE',\n",
    "                                        'trin + tobago':'Trinidad and Tobago','trinidad tobago':'Trinidad and Tobago'})\n",
    "    \n",
    "    df['Country'] = df['Country'].str.lower()\n",
    "    df['global_north']=0\n",
    "    df['global_north'].loc[df['Country'].isin(westernworld)]=1\n",
    "\n",
    "    if dataset=='HC':\n",
    "        dataset='highlycited'\n",
    "        df.to_csv(\"dworkin_code_api/coreidd/df8_\"+dataset+\"_\"+str(threshold)+'.csv')\n",
    "    else: \n",
    "        df.to_csv(\"dworkin_code_api/books/\"+dataset+\"_\"+str(threshold)+'.csv')\n",
    "\n",
    "thresholding(.7,'HC')\n",
    "thresholding(.6,'HC')\n",
    "thresholding(.8,'HC')\n",
    "thresholding(.7,'books')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
